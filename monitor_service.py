#!/usr/bin/env python3
import json
import logging
import os
import re
import time
import signal
import sys
from pathlib import Path
from urllib.parse import urljoin

import requests
from playwright.sync_api import sync_playwright

from extract_case_entries import build_patterns, parse_entries
from env_loader import load_dotenv


CASE_ID_RE = re.compile(r"^(?P<case_id>\d{8})\.txt$")
META_LINE_RE = re.compile(r"^(ã€.*ã€‘|\[.*\])$")
LOG_LINE_RE = re.compile(
    r"^\s*(\d{4}-\d{2}-\d{2}|\d{2}:\d{2}:\d{2}|INFO|ERROR|DEBUG|TRACE|WARN|WARNING)\b"
)
JSON_LINE_RE = re.compile(r"^\s*[{[].*[}\]]\s*$")
DEFAULT_LLM_PROMPT = """ã‚ãªãŸã¯ã‚µãƒãƒ¼ãƒˆãƒã‚±ãƒƒãƒˆã®å†…å®¹æ•´åˆæ€§ã‚’ç¢ºèªã™ã‚‹AIã§ã™ã€‚

å…¥åŠ›ã¨ã—ã¦ã€ã‚ã‚‹æ¡ˆä»¶ï¼ˆãƒã‚±ãƒƒãƒˆï¼‰ã«é–¢ã™ã‚‹å±¥æ­´ãŒæ™‚ç³»åˆ—é †ã«ä¸ãˆã‚‰ã‚Œã¾ã™ã€‚
å„å±¥æ­´ã¯ä»¥ä¸‹ã®æ§‹é€ ã‚’æŒã¡ã¾ã™ï¼š
- type: question (è³ªå•) ã¾ãŸã¯ answer (å›ç­”)
- created_on: ä½œæˆæ—¥æ™‚
- text: è³ªå•ã¾ãŸã¯å›ç­”ã®æœ¬æ–‡ã¨ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆãƒ­ã‚°ã‚„ãƒã‚¤ã‚ºã¯å‰Šé™¤æ¸ˆã¿ï¼‰

ã‚ãªãŸã®ä»»å‹™ã¯ã€ã€Œæœ€å¾Œã®å›ç­”ï¼ˆtype=answerï¼‰ã€ãŒ
æœ¬å½“ã«ã“ã®æ¡ˆä»¶ã®ç›´è¿‘ã®è³ªå•ï¼ˆtype=questionï¼‰ã«å¯¾ã™ã‚‹
æ–‡è„ˆçš„ã«æ­£ã—ã„å›ç­”ã§ã‚ã‚‹ã‹ã©ã†ã‹ã‚’åˆ¤å®šã™ã‚‹ã“ã¨ã§ã™ã€‚

### åˆ¤å®šã®ãƒã‚¤ãƒ³ãƒˆï¼š
- å†…å®¹ã®æ­£ç¢ºæ€§ãƒ»å“è³ªã¯è©•ä¾¡ã—ãªã„ï¼ˆä¾‹ï¼šå›ç­”ãŒæ­£ã—ã„ã‹ã©ã†ã‹ã¯ç„¡é–¢ä¿‚ï¼‰ã€‚
- ã‚ãã¾ã§ **è©±ã®æµã‚Œãƒ»æ–‡è„ˆã®æ•´åˆæ€§** ã®ã¿ã‚’åˆ¤æ–­ã™ã‚‹ã€‚
- ã€Œåˆ¥æ¡ˆä»¶ã®è©±é¡Œã€ã€Œå…¨ãç•°ãªã‚‹ãƒ†ãƒ¼ãƒã€ã€Œæ˜ã‚‰ã‹ã«é–¢ä¿‚ãªã„æ–‡è„ˆã€ãªã‚‰å–ã‚Šé•ãˆã®å¯èƒ½æ€§ã‚ã‚Šã€‚
- å—ä»˜ç•ªå·ãªã©ã®IDã‚„æ¡ˆä»¶åã®åˆ¤å®šã¯ã™ã§ã«å‰å‡¦ç†æ¸ˆã¿ã€‚ã“ã“ã§ã¯å›ç­”ã®å†…å®¹ã®ã¿ã€åŒæ¡ˆä»¶ã®å†…å®¹ã§ã‚ã‚‹ã‹ã®ã¿åˆ¤æ–­ã™ã‚‹ã€‚

### å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆï¼š
å¿…ãšä»¥ä¸‹ã®å½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ï¼š

æŸ»é–²çµæœï¼š<æ‰¿èª|å´ä¸‹|ä¸æ˜>
ç†ç”±ï¼š<å®¢è¦³çš„ãªç†ç”±>

#### å®šç¾©ï¼š
- **æ‰¿èª**ï¼šæœ€å¾Œã®å›ç­”ãŒã€åŒã˜æ¡ˆä»¶ã«é–¢ã™ã‚‹è³ªå•ã«è‡ªç„¶ã«å¯¾å¿œã—ã¦ã„ã‚‹ã€‚
- **å´ä¸‹**ï¼šæœ€å¾Œã®å›ç­”ãŒã€ç•°ãªã‚‹æ¡ˆä»¶ãƒ»åˆ¥ãƒ†ãƒ¼ãƒãƒ»æ–‡è„ˆã®ç•°ãªã‚‹è³ªå•ã«å¯¾å¿œã—ã¦ã„ã‚‹ã€‚
- **ä¸æ˜**ï¼šæƒ…å ±ãŒå°‘ãªã™ãã‚‹ãƒ»æ–‡è„ˆãŒåˆ¤æ–­ã§ããªã„ã€‚

### å±¥æ­´
{entries}
"""

STOP_REQUESTED = False
FORCE_STOP = False


def handle_stop_signal(signum, _frame):
    global STOP_REQUESTED, FORCE_STOP
    if STOP_REQUESTED:
        FORCE_STOP = True
        logging.error("å¼·åˆ¶åœæ­¢ã‚·ã‚°ãƒŠãƒ«(%s)ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚å³æ™‚çµ‚äº†ã—ã¾ã™ã€‚", signum)
        sys.exit(1)
    STOP_REQUESTED = True
    logging.info("åœæ­¢ã‚·ã‚°ãƒŠãƒ«(%s)ã‚’å—ä¿¡ã—ã¾ã—ãŸã€‚ç¾åœ¨ã®å‡¦ç†ãŒçµ‚ã‚ã‚Šæ¬¡ç¬¬åœæ­¢ã—ã¾ã™ã€‚", signum)


def build_url(base_url, case_id):
    if "?" in base_url or base_url.endswith("="):
        return f"{base_url}{case_id}"
    base = base_url if base_url.endswith("/") else base_url + "/"
    return urljoin(base, case_id)


def normalize_url(url):
    return url.rstrip("/")


def login_if_needed(page, login_url, username, password, selectors):
    if normalize_url(page.url).startswith(normalize_url(login_url)):
        page.fill(selectors["username"], username)
        page.fill(selectors["password"], password)
        page.click(selectors["submit"])
        try:
            page.wait_for_url(
                lambda url: not normalize_url(url).startswith(normalize_url(login_url)),
                timeout=30000,
            )
        except Exception:
            pass
        page.wait_for_load_state("load")


def collect_page_content(page):
    parts = []
    main_url = page.url
    parts.append(f"<!-- main frame url={main_url} -->")
    parts.append(page.content())
    for frame in page.frames:
        if frame == page.main_frame:
            continue
        frame_url = frame.url or "about:blank"
        if frame_url == "about:blank":
            continue
        try:
            frame_content = frame.content()
        except Exception as exc:
            logging.debug("ãƒ•ãƒ¬ãƒ¼ãƒ å†…å®¹ã®å–å¾—ã«å¤±æ•—ã—ã¾ã—ãŸ: %s (%s)", frame_url, exc)
            continue
        parts.append(f"<!-- frame url={frame_url} -->")
        parts.append(frame_content)
    return "\n".join(parts)


def collect_visible_text(page):
    def extract_text(frame):
        try:
            return frame.evaluate(
                """
                () => {
                  const parts = [];
                  const walk = (node) => {
                    if (!node) return;
                    if (node.nodeType === Node.TEXT_NODE) {
                      const text = node.textContent && node.textContent.trim();
                      if (text) parts.push(text);
                      return;
                    }
                    if (
                      node.nodeType !== Node.ELEMENT_NODE &&
                      node.nodeType !== Node.DOCUMENT_FRAGMENT_NODE
                    ) {
                      return;
                    }
                    if (node.shadowRoot) walk(node.shadowRoot);
                    for (const child of node.childNodes || []) {
                      walk(child);
                    }
                  };
                  walk(document.body || document.documentElement);
                  return parts.join("\\n");
                }
                """
            )
        except Exception as exc:
            logging.debug("ãƒ†ã‚­ã‚¹ãƒˆæŠ½å‡ºã«å¤±æ•—ã—ã¾ã—ãŸ: %s (%s)", frame.url, exc)
            return ""

    parts = []
    main_text = extract_text(page.main_frame)
    if main_text:
        parts.append(f"<!-- main frame url={page.url} -->")
        parts.append(main_text)
    for frame in page.frames:
        if frame == page.main_frame:
            continue
        frame_text = extract_text(frame)
        if frame_text:
            frame_url = frame.url or "about:blank"
            parts.append(f"<!-- frame url={frame_url} -->")
            parts.append(frame_text)
    return "\n".join(parts)


def fetch_case_text(case_id, base_url, work_dir, browser_settings, login_settings):
    url = build_url(base_url, case_id)
    output_path = work_dir / f"{case_id}.txt"

    launch_args = []
    if browser_settings["profile_dir"]:
        launch_args.append(f"--profile-directory={browser_settings['profile_dir']}")

    selectors = login_settings["selectors"]

    # ãƒ­ã‚°ã‚¤ãƒ³æ¸ˆã¿ã®Chromeãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½¿ãˆã‚‹å ´åˆã¯æ°¸ç¶šã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½¿ã†ã€‚
    with sync_playwright() as p:
        if browser_settings["user_data_dir"]:
            context = p.chromium.launch_persistent_context(
                user_data_dir=browser_settings["user_data_dir"],
                channel=browser_settings["channel"],
                headless=browser_settings["headless"],
                args=launch_args,
            )
            page = context.pages[0] if context.pages else context.new_page()
        else:
            browser = p.chromium.launch(
                channel=browser_settings["channel"],
                headless=browser_settings["headless"],
                args=launch_args,
            )
            context = browser.new_context()
            page = context.new_page()

        try:
            page.goto(url, wait_until="load", timeout=30000)
            login_if_needed(
                page,
                login_url=login_settings["url"],
                username=login_settings["username"],
                password=login_settings["password"],
                selectors=selectors,
            )
            if normalize_url(page.url).startswith(normalize_url(login_settings["url"])):
                page.goto(url, wait_until="load", timeout=30000)
            try:
                page.wait_for_load_state("networkidle", timeout=30000)
            except Exception:
                logging.debug("networkidleå¾…æ©ŸãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚")
            if browser_settings["wait_seconds"] > 0:
                logging.info("ãƒšãƒ¼ã‚¸è¡¨ç¤ºå¾Œã«%sç§’å¾…æ©Ÿã—ã¾ã™ã€‚", browser_settings["wait_seconds"])
                page.wait_for_timeout(browser_settings["wait_seconds"] * 1000)
            page_html = collect_page_content(page)
            page_text = collect_visible_text(page)
            if not page_text.strip() and page_html.strip():
                logging.info("ãƒ†ã‚­ã‚¹ãƒˆãŒç©ºã®ãŸã‚HTMLã‚’ä¿å­˜ã—ã¾ã™ã€‚")
            body_text = page_text.strip() or page_html
            logging.debug(
                "å–å¾—å†…å®¹: html_chars=%s text_chars=%s",
                len(page_html),
                len(page_text),
            )
        finally:
            if browser_settings["keep_open"]:
                logging.info("ãƒ–ãƒ©ã‚¦ã‚¶ã‚’é–‰ã˜ã‚‹å‰ã«å¾…æ©Ÿã—ã¾ã™ã€‚Enterã§çµ‚äº†ã—ã¾ã™ã€‚")
                try:
                    input()
                except EOFError:
                    pass
            context.close()

    output_path.write_text(body_text, encoding="utf-8")
    return output_path


def clean_entry_data(text):
    # è¦‹å‡ºã—ã‚„ãƒ©ãƒ™ãƒ«ãªã©ã®ãƒ¡ã‚¿è¡Œã‚’é™¤å»ã—ã¦æœ¬æ–‡ã ã‘æ®‹ã™ã€‚
    cleaned = []
    for line in text.splitlines():
        stripped = line.strip()
        if not stripped:
            continue
        if META_LINE_RE.match(stripped):
            continue
        cleaned.append(line)
    return "\n".join(cleaned).strip()


def remove_logs(text, log_filter):
    if not text:
        return ""
    max_line_len = log_filter["max_line_len"]
    removed = 0
    filtered = []
    for line in text.splitlines():
        stripped = line.strip()
        if not stripped:
            continue
        if LOG_LINE_RE.match(stripped):
            removed += 1
            continue
        if JSON_LINE_RE.match(stripped):
            removed += 1
            continue
        if len(stripped) > max_line_len:
            removed += 1
            continue
        filtered.append(line)
    logging.debug("log_filter: removed=%s kept=%s", removed, len(filtered))
    return "\n".join(filtered).strip()


def trim_entries(entries, max_chars):
    # æ—¢ã«æ–°ã—ã„é †ãªã®ã§ã€æ–‡å­—æ•°ä¸Šé™ã¾ã§é †ã«è©°ã‚ã‚‹ã€‚
    trimmed = []
    total = 0
    for entry in entries:
        data = entry["data"]
        if not data:
            continue
        if total >= max_chars:
            break
        remaining = max_chars - total
        if len(data) > remaining:
            data = data[:remaining]
        trimmed.append({**entry, "data": data})
        total += len(data)
        if total >= max_chars:
            break
    return trimmed


def build_case_json(case_text, max_chars, log_filter):
    # æŠ½å‡ºâ†’æ•´å½¢â†’LLMã«æ¸¡ã™ã‚µã‚¤ã‚ºã¾ã§åˆ‡ã‚Šè©°ã‚ã‚‹ã€‚
    separator_re, header_re, question_keyword, answer_keyword = build_patterns()
    entries = parse_entries(case_text, separator_re, header_re, question_keyword, answer_keyword)
    cleaned_entries = []
    for entry in entries:
        original_data = entry["data"]
        cleaned = clean_entry_data(original_data)
        if not cleaned and original_data:
            logging.debug(
                "clean_entry_dataã§å…¨å‰Šé™¤ã•ã‚ŒãŸãŸã‚å…ƒã®å†…å®¹ã‚’ä¿æŒã—ã¾ã™: type=%s",
                entry["type"],
            )
            cleaned = original_data
        original_cleaned = cleaned
        if log_filter["enabled"]:
            cleaned = remove_logs(cleaned, log_filter)
            if not cleaned and original_cleaned:
                logging.debug(
                    "log_filterã§å…¨å‰Šé™¤ã•ã‚ŒãŸãŸã‚å…ƒã®å†…å®¹ã‚’ä¿æŒã—ã¾ã™: type=%s",
                    entry["type"],
                )
                cleaned = original_cleaned
        if not cleaned:
            logging.debug("ç©ºã‚¨ãƒ³ãƒˆãƒªã®ãŸã‚é™¤å¤–ã—ã¾ã™: type=%s", entry["type"])
            continue
        logging.debug("entry cleaned: type=%s chars=%s", entry["type"], len(cleaned))
        cleaned_entries.append({**entry, "data": cleaned})
    return trim_entries(cleaned_entries, max_chars)


def build_llm_url(base_url):
    # ãƒ™ãƒ¼ã‚¹URL/ãƒ•ãƒ«ãƒ‘ã‚¹ã®ã©ã¡ã‚‰ã§ã‚‚å—ã‘ä»˜ã‘ã‚‹ã€‚
    base = base_url.rstrip("/")
    if base.endswith("/chat/completions"):
        return base
    return f"{base}/chat/completions"


def call_llm(case_id, entries_payload, settings):
    prompt_template = settings["prompt"] or DEFAULT_LLM_PROMPT
    # {entries} ç½®æ›ãŒä½¿ãˆã‚‹ã‚ˆã†ã«ãƒ†ãƒ³ãƒ—ãƒ¬ãƒ¼ãƒˆå½¢å¼ã‚’ç¶­æŒã€‚
    if "{entries}" not in prompt_template:
        print("WARNING: LLM_PROMPTã«{entries}ãŒå«ã¾ã‚Œã¦ã„ã¾ã›ã‚“ã€‚", flush=True)
    prompt = prompt_template.replace("{entries}", entries_payload)
    messages = [
        {"role": "system", "content": prompt},
        {"role": "user", "content": f"Case ID: {case_id} ã®åˆ¤å®šã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚"},
    ]

    request_body = {
        "model": settings["model"],
        "messages": messages,
        "temperature": settings["temperature"],
    }

    headers = {"Content-Type": "application/json"}
    if settings["api_key"]:
        headers["Authorization"] = f"Bearer {settings['api_key']}"

    cert_file = settings.get("cert_file") or None
    response = requests.post(
        build_llm_url(settings["base_url"]),
        headers=headers,
        json=request_body,
        timeout=settings["timeout"],
        cert=cert_file,
    )
    response.raise_for_status()
    data = response.json()
    return data["choices"][0]["message"]["content"]


def parse_llm_json(text):
    # å‰å¾Œã«ä½™è¨ˆãªæ–‡ãŒã‚ã£ã¦ã‚‚JSONã ã‘æ‹¾ãˆã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        start = text.find("{")
        end = text.rfind("}")
        if start == -1 or end == -1 or end <= start:
            return None
        try:
            return json.loads(text[start : end + 1])
        except json.JSONDecodeError:
            return None


def parse_llm_judgement(text):
    # æ—¢å®šãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®æ—¥æœ¬èªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã«å¯¾å¿œã€‚
    result_match = re.search(r"æŸ»é–²çµæœï¼š\s*(æ‰¿èª|å´ä¸‹|ä¸æ˜)", text)
    reason_match = re.search(r"ç†ç”±ï¼š\s*(.+)", text)
    result = result_match.group(1) if result_match else None
    reason = reason_match.group(1).strip() if reason_match else None
    return result, reason


def notify_teams(case_id, llm_text, llm_json, webhook_urls):
    if not webhook_urls:
        return
    if isinstance(webhook_urls, str):
        webhook_urls = [webhook_urls]
    webhook_urls = [url for url in webhook_urls if url]
    if not webhook_urls:
        return
    result, reason = parse_llm_judgement(llm_text)
    # ä¸ä¸€è‡´ã‚¢ãƒ©ãƒ¼ãƒˆã¯å°‚ç”¨ã®ã‚µãƒãƒªãƒ¼ã‚’ä½¿ã†ã€‚
    summary = f"Case ID {case_id} {result or ''}".strip()
    if result == "å´ä¸‹":
        summary = f"Case ID {case_id} caseid mismatch"
    card_body = build_adaptive_card_body(
        case_id=case_id,
        result=result or "ä¸æ˜",
        reason=reason,
        llm_text=llm_text,
    )
    send_adaptive_card(webhook_urls, card_body, summary=summary)


def build_adaptive_card_body(case_id, result, reason, llm_text):
    # æ—¢å­˜ã®é€šçŸ¥ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆã«åˆã‚ã›ã¦ã‚«ãƒ¼ãƒ‰ã‚’çµ„ã¿ç«‹ã¦ã‚‹ã€‚
    case_url = build_url(os.environ.get("BASE_URL", "http://localhost:8080/"), case_id)
    if result == "å´ä¸‹":
        return [
            {
                "type": "Container",
                "style": "attention",
                "items": [
                    {
                        "type": "TextBlock",
                        "text": "ğŸš¨ å—ä»˜ç•ªå·ä¸ä¸€è‡´ã®å¯èƒ½æ€§",
                        "size": "Large",
                        "weight": "Bolder",
                        "color": "Attention",
                        "wrap": True,
                    },
                    {
                        "type": "TextBlock",
                        "text": f"[Case #{case_id}]({case_url})",
                        "wrap": True,
                        "spacing": "Small",
                    },
                    {
                        "type": "TextBlock",
                        "text": "LLMãŒ caseid mismatch ã‚’æ¤œçŸ¥ã—ã¾ã—ãŸã€‚ç•°ãªã‚‹å—ä»˜ç•ªå·ã¸ã®å›ç­”ãŒç”³å‘Šã•ã‚Œã¦ã„ã¾ã™ã€‚è‡³æ€¥ç¢ºèªã—ã¦ãã ã•ã„ã€‚",
                        "wrap": True,
                        "spacing": "Medium",
                        "color": "Attention",
                    },
                    {
                        "type": "TextBlock",
                        "text": f"ç†ç”±ï¼š{reason or llm_text}",
                        "wrap": True,
                        "spacing": "Small",
                    },
                ],
                "bleed": True,
            }
        ]
    if result == "æ‰¿èª":
        emoji = "âœ…"
        items = [
            {
                "type": "TextBlock",
                "text": f"{emoji} **ãƒã‚±ãƒƒãƒˆæ‰¿èª**",
                "size": "Large",
                "weight": "Bolder",
                "color": "Good",
                "wrap": True,
            },
            {
                "type": "TextBlock",
                "text": f"[Case #{case_id}]({case_url})",
                "wrap": True,
                "spacing": "Small",
            },
        ]
        if reason:
            items.append(
                {"type": "TextBlock", "text": f"ç†ç”±ï¼š{reason}", "wrap": True}
            )
        else:
            items.append({"type": "TextBlock", "text": llm_text, "wrap": True})
        return [{"type": "Container", "items": items, "bleed": True}]

    emoji = "â”"
    return [
        {
            "type": "Container",
            "items": [
                {
                    "type": "TextBlock",
                    "text": f"{emoji} åˆ¤å®šä¸æ˜",
                    "size": "Large",
                    "weight": "Bolder",
                    "wrap": True,
                },
                {
                    "type": "TextBlock",
                    "text": f"[Case #{case_id}]({case_url})",
                    "wrap": True,
                    "spacing": "Small",
                },
                {
                    "type": "TextBlock",
                    "text": llm_text,
                    "wrap": True,
                },
            ],
        }
    ]


def send_adaptive_card(webhooks, body, summary, success_label=None):
    # Teamså‘ã‘ã®Adaptive Cardã¨ã—ã¦é€ä¿¡ã™ã‚‹ã€‚
    card = {
        "type": "message",
        "summary": summary,
        "attachments": [
            {
                "contentType": "application/vnd.microsoft.card.adaptive",
                "content": {
                    "$schema": "http://adaptivecards.io/schemas/adaptive-card.json",
                    "type": "AdaptiveCard",
                    "version": "1.4",
                    "body": body,
                },
            }
        ],
    }
    if success_label:
        card["summary"] = f"{summary} ({success_label})"

    for webhook in webhooks:
        if not webhook:
            continue
        requests.post(webhook, json=card, timeout=10)


def wait_for_stable_size(path, retries=5, interval=1.0):
    # æ›¸ãè¾¼ã¿ä¸­ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¾ãªã„ã‚ˆã†ã«ã™ã‚‹ã€‚
    last_size = -1
    for _ in range(retries):
        if STOP_REQUESTED:
            return False
        try:
            size = path.stat().st_size
        except FileNotFoundError:
            return False
        if size == last_size:
            return True
        last_size = size
        time.sleep(interval)
    logging.debug("ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒå®‰å®šã—ã¾ã›ã‚“ã§ã—ãŸ: %s", path)
    return True


def process_case(case_id, settings):
    work_dir = settings["work_dir"]
    work_dir.mkdir(parents=True, exist_ok=True)

    try:
        case_text_path = fetch_case_text(
            case_id,
            base_url=settings["base_url"],
            work_dir=work_dir,
            browser_settings=settings["browser"],
            login_settings=settings["login"],
        )

        case_text = case_text_path.read_text(encoding="utf-8")
        logging.debug("Case ID %s: fetched text length=%s", case_id, len(case_text))
        logging.debug("Case ID %s: fetched text preview=%r", case_id, case_text[:800])

        entries = build_case_json(case_text, settings["max_chars"], settings["log_filter"])
        logging.debug("Case ID %s: extracted entries=%s", case_id, len(entries))
        if not entries:
            logging.info("case_id=%s result=skipped reason=no_entries", case_id)
            return
        if entries[-1]["type"].lower() != "answer":
            if settings["llm"]["allow_partial"]:
                last_answer_index = None
                for idx in range(len(entries) - 1, -1, -1):
                    if entries[idx]["type"].lower() == "answer":
                        last_answer_index = idx
                        break
                if last_answer_index is None:
                    logging.info(
                        "case_id=%s result=skipped reason=no_answer_entry",
                        case_id,
                    )
                    return
                entries = entries[: last_answer_index + 1]
                logging.info(
                    "case_id=%s result=partial reason=last_entry_not_answer entries=%s",
                    case_id,
                    len(entries),
                )
            else:
                logging.info(
                    "case_id=%s result=skipped reason=last_entry_not_answer",
                    case_id,
                )
                return
        output_path = work_dir / f"{case_id}.json"
        output_path.write_text(
            json.dumps(entries, ensure_ascii=False, indent=4),
            encoding="utf-8",
        )

        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ã‚¹ã‚­ãƒ¼ãƒï¼ˆtype/created_on/textï¼‰ã«åˆã‚ã›ã‚‹ã€‚
        llm_entries = [
            {
                "type": entry["type"].lower(),
                "created_on": entry["date"],
                "text": entry["data"],
            }
            for entry in entries
        ]
        llm_input = json.dumps(llm_entries, ensure_ascii=False, indent=2)
        logging.debug("Case ID %s: llm input=%s", case_id, llm_input)
        llm_text = call_llm(case_id, llm_input, settings["llm"])
        llm_json = parse_llm_json(llm_text)
        judgement, _reason = parse_llm_judgement(llm_text)

        decision_value = None
        if judgement:
            decision_value = judgement
        elif llm_json and isinstance(llm_json, dict):
            decision_value = str(llm_json.get("decision", "")).lower()

        webhooks = [settings["teams"]["default"]]
        if decision_value in {"å´ä¸‹", "reject", "rejected", "ng", "fail"}:
            webhooks.append(settings["teams"]["reject"])
        if settings["teams"]["enabled"]:
            notify_teams(case_id, llm_text, llm_json, webhooks)
        logging.info("case_id=%s result=%s", case_id, decision_value or "unknown")
    except Exception:
        logging.exception("Case ID %s: failed to process", case_id)


def monitor_directory(settings):
    # è¿½åŠ ä¾å­˜ã‚’é¿ã‘ã‚‹ãŸã‚ãƒãƒ¼ãƒªãƒ³ã‚°ã§ç›£è¦–ã™ã‚‹ã€‚
    monitor_dir = settings["monitor_dir"]
    monitor_dir.mkdir(parents=True, exist_ok=True)
    case_id_re = re.compile(rf"^(?P<case_id>\d{{{settings['case_id_digits']}}})\.txt$")
    logging.debug(
        "monitor_dir=%s process_existing=%s poll_interval=%s case_id_digits=%s",
        monitor_dir,
        settings["process_existing"],
        settings["poll_interval"],
        settings["case_id_digits"],
    )

    processed = set()
    if not settings["process_existing"]:
        for entry in monitor_dir.iterdir():
            if entry.is_file() and case_id_re.match(entry.name):
                processed.add(entry)
        logging.debug("åˆæœŸæ—¢å­˜ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™¤å¤–ã—ã¾ã—ãŸ: %s", len(processed))

    while True:
        try:
            logging.debug("ã‚¹ã‚­ãƒ£ãƒ³ä¸­: %s", monitor_dir)
            for path in sorted(monitor_dir.iterdir()):
                if STOP_REQUESTED:
                    logging.info("åœæ­¢è¦æ±‚ã«ã‚ˆã‚Šç›£è¦–ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                    return
                if not path.is_file():
                    continue
                match = case_id_re.match(path.name)
                if not match:
                    continue
                if path in processed:
                    continue
                logging.debug("å‡¦ç†å¯¾è±¡ã‚’æ¤œå‡º: %s", path)
                if not wait_for_stable_size(path):
                    continue
                case_id = match.group("case_id")
                process_case(case_id, settings)
                processed.add(path)
                try:
                    path.unlink()
                    logging.debug("å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤ã—ã¾ã—ãŸ: %s", path)
                except FileNotFoundError:
                    pass
                if STOP_REQUESTED:
                    logging.info("åœæ­¢è¦æ±‚ã«ã‚ˆã‚Šç›£è¦–ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                    return
        except Exception:
            logging.exception("Monitor loop error")
        time.sleep(settings["poll_interval"])


def load_settings():
    # ç’°å¢ƒå¤‰æ•°ã¨ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‹ã‚‰è¨­å®šã‚’çµ„ã¿ç«‹ã¦ã‚‹ã€‚
    base_dir = Path(__file__).resolve().parent
    return {
        "monitor_dir": Path(os.environ.get("MONITOR_DIR", base_dir / "monitor")),
        "work_dir": Path(os.environ.get("WORK_DIR", base_dir / "work")),
        "case_id_digits": int(os.environ.get("CASE_ID_DIGITS", "8") or "8"),
        "poll_interval": float(os.environ.get("POLL_INTERVAL", "2")),
        "process_existing": os.environ.get("PROCESS_EXISTING", "").lower()
        in {"1", "true", "yes"},
        "base_url": os.environ.get("BASE_URL", "http://localhost:8080/"),
        "max_chars": int(os.environ.get("MAX_CHARS", "6000")),
        "log_filter": {
            "enabled": os.environ.get("LOG_FILTER_ENABLED", "true").lower()
            in {"1", "true", "yes"},
            "max_line_len": int(os.environ.get("LOG_FILTER_MAX_LINE_LEN", "200")),
        },
        "browser": {
            "user_data_dir": os.environ.get("CHROME_USER_DATA_DIR"),
            "profile_dir": os.environ.get("CHROME_PROFILE_DIR"),
            "channel": os.environ.get("BROWSER_CHANNEL", "chrome"),
            "headless": os.environ.get("HEADLESS", "").lower() in {"1", "true", "yes"},
            "keep_open": os.environ.get("KEEP_BROWSER_OPEN", "").lower()
            in {"1", "true", "yes"}
            or os.environ.get("KEEP_BROWER_OPEN", "").lower() in {"1", "true", "yes"},
            "wait_seconds": int(os.environ.get("WAIT_SECONDS", "0") or "0"),
        },
        "login": {
            "url": os.environ.get("LOGIN_URL", "http://localhost:8080/login"),
            "username": os.environ.get("LOGIN_USERNAME", "testuser"),
            "password": os.environ.get("LOGIN_PASSWORD", "password"),
            "selectors": {
                "username": os.environ.get(
                    "LOGIN_USERNAME_SELECTOR", "input[name='username']"
                ),
                "password": os.environ.get(
                    "LOGIN_PASSWORD_SELECTOR", "input[name='password']"
                ),
                "submit": os.environ.get(
                    "LOGIN_SUBMIT_SELECTOR",
                    "button[type='submit'], input[type='submit']",
                ),
            },
        },
        "llm": {
            "base_url": os.environ.get("LLM_BASE_URL", "http://localhost:11434/v1"),
            "api_key": os.environ.get("LLM_API_KEY", ""),
            "model": os.environ.get("LLM_MODEL", "llama3.2:1b"),
            "prompt": os.environ.get("LLM_PROMPT", ""),
            "temperature": float(os.environ.get("LLM_TEMPERATURE", "0.2")),
            "timeout": int(os.environ.get("LLM_TIMEOUT", "60")),
            "cert_file": os.environ.get("LLM_CERT_FILE", ""),
            "allow_partial": os.environ.get("LLM_ALLOW_PARTIAL", "").lower()
            in {"1", "true", "yes"},
        },
        "teams": {
            "enabled": os.environ.get("TEAMS_ENABLED", "true").lower()
            in {"1", "true", "yes"},
            "default": os.environ.get("TEAMS_WEBHOOK_URL", ""),
            "reject": os.environ.get("TEAMS_REJECT_WEBHOOK_URL", ""),
        },
        "logging": {
            "enabled": os.environ.get("LOG_ENABLED", "true").lower()
            in {"1", "true", "yes"},
            "level": os.environ.get("LOG_LEVEL", "INFO").upper(),
        },
    }


def main():
    load_dotenv()
    settings = load_settings()
    if settings["logging"]["enabled"]:
        logging.basicConfig(
            level=settings["logging"]["level"],
            format="%(asctime)s %(levelname)s %(message)s",
        )
    else:
        logging.disable(logging.CRITICAL)
    signal.signal(signal.SIGINT, handle_stop_signal)
    signal.signal(signal.SIGTERM, handle_stop_signal)
    monitor_directory(settings)


if __name__ == "__main__":
    main()
